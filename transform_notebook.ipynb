{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/transformer_soc/rolling_and_plot.py .\n",
    "!cp /content/drive/MyDrive/transformer_soc/220617_soc.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_OpwqWL2QH5G"
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "# removes tensorflow warnings triggered because of Tensorflow incompatibility with my Apple M1 chip.\n",
    "# ignore this when using a non Apple Silicon device, ie. Google Colab or the likes.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Input, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformer_helper import *\n",
    "from rolling_and_plot import data_plot, rolling_split, normalize, validate\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will have to figure out how to set device to cuda in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Import](#0)\n",
    "- [Preprocessing](#win)\n",
    "- [Encoder](#enc)\n",
    "    - [Encoder Layer](#enc-lay)\n",
    "    - [Full Encoder](#full-enc)\n",
    "- [Decoder](#dec)\n",
    "    - [Decoder Layer](#dec-lay)\n",
    "    - [Full Decoder](#full-dec)\n",
    "- [Transformer](#transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature:\n",
    "\n",
    "\n",
    "According to [A Transformer-based Framework for Multivariate Time Series Representation Learning](https://dl.acm.org/doi/abs/10.1145/3447548.3467401):\n",
    "Using **Batch Normalization is significantly more effective** for multivariate time-series than using the traditional Layer Normalization method found in NLP.\n",
    "\n",
    "In addition, according to [Deep learning approach towards accurate state of charge estimation for lithium-ion batteries using self-supervised transformer model](https://www.nature.com/articles/s41598-021-98915-8#Sec9):\n",
    "Using a transformer network while **forgoing the Decoder Layer** is more effective for the application of State-of-Charge estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG0gPyv0oDBi"
   },
   "source": [
    "$\\large{Self\\ Attention}$\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large{Input}$\n",
    "\n",
    "Voltage, Current, SOC at times:\n",
    "$$t - window\\_size - 1 \\rightarrow t - 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Cannot use embedding layers with battery data because of floating point values and negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class G:\n",
    "    num_features = 3 # current, voltage, and soc at t minus G.window_size -> t minus 1\n",
    "    window_size = 64\n",
    "    batch_size = 16\n",
    "    epochs = 10\n",
    "    dense_dim = 32\n",
    "    model_dim = 128\n",
    "    num_heads = 16\n",
    "    num_layers = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"win\"></a>\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "file = pd.read_csv(\"/content/220617_soc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot(data = [file],\n",
    "          title=\"OCV v SOC\",\n",
    "          x = [\"test time (sec)\"],\n",
    "          y = [\"soc\"],\n",
    "          markers = \"lines\",\n",
    "          color = \"darkorchid\",\n",
    "          x_title = \"Test Time (sec)\",\n",
    "          y_title = \"SOC\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = normalize(file.loc[:,[\"current\",\"voltage\",\"soc\"]].iloc[::5])\n",
    "#uses sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = rolling_split(file, G.window_size)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n",
    "#uses sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blS0pEpTqRVI"
   },
   "source": [
    "<a name='enc'></a>\n",
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "sC5vJhz29vZR"
   },
   "outputs": [],
   "source": [
    "def FullyConnected(dense_dim = G.dense_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dense_dim, activation='relu'),  # (G.batch_size, G.dense_dim)\n",
    "        tf.keras.layers.Dense(dense_dim, activation='relu'),  # (G.batch_size, G.dense_dim)\n",
    "        tf.keras.layers.Dense(G.num_features)  # (G.batch_size, G.num_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R65WbX5wqYYH"
   },
   "source": [
    "<a name='enc-lay'></a>\n",
    "###  Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "tIufbrc-9_2u"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This archirecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by batch normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_heads,\n",
    "                 num_features,\n",
    "                 dense_dim,\n",
    "                 dropout_rate=0.1,\n",
    "                 batchnorm_eps=1e-6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(num_heads = num_heads,\n",
    "                                      key_dim = num_features,\n",
    "                                      dropout = dropout_rate,\n",
    "                                     )\n",
    "        #feed-forward-network\n",
    "        self.ffn = FullyConnected(dense_dim = dense_dim)\n",
    "        \n",
    "        \n",
    "        self.batchnorm1 = BatchNormalization(epsilon=batchnorm_eps)\n",
    "        self.batchnorm2 = BatchNormalization(epsilon=batchnorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (G.batch_size, G.window_size, G.num_features)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (G.batch_size, G.window_size, G.num_features)\n",
    "        \"\"\"\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        attn_output = self.mha(query = x,\n",
    "                               value = x) # Self attention\n",
    "        \n",
    "        out1 = self.batchnorm1(tf.add(x, attn_output))  # (G.batch_size, G.window_size, G.dense_dim)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "    \n",
    "        ffn_output =  self.dropout_ffn(ffn_output)\n",
    "        \n",
    "        encoder_layer_out = self.batchnorm2(tf.add(ffn_output, out1))\n",
    "        # (G.batch_size, G.window_size, G.num_features)\n",
    "        return encoder_layer_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='full-enc'></a>\n",
    "### Full Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "7j2Tjr0K0t0I"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self,\n",
    "                 num_layers = G.num_layers,\n",
    "                 num_heads = G.num_heads,\n",
    "                 num_features = G.num_features,\n",
    "                 dense_dim = G.dense_dim,\n",
    "                 input_size = G.num_features,\n",
    "                 maximum_position_encoding = G.window_size,\n",
    "                 dropout_rate=0.1,\n",
    "                 batchnorm_eps=1e-6):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "#         self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "#         self.embedding = Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                input_size)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(num_heads = num_heads,\n",
    "                                        num_features = num_features,\n",
    "                                        dense_dim = dense_dim,\n",
    "                                        dropout_rate = dropout_rate,\n",
    "                                        batchnorm_eps = batchnorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (G.batch_size, G.window_size, G.num_features)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            out2 -- Tensor of shape (G.batch_size, G.window_size, G.dense_dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x,training)\n",
    "            \n",
    "        # only need the final time's data : time = t-1 from the window\n",
    "        # x has shape (G.batch_size, G.window_size, G.dense_dim)\n",
    "        # but I am only returning time t-1:\n",
    "        return x[:, -1, :] # (G.batch_size, G.dense_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='transform'></a> \n",
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "QHymPmaj-2ba"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_layers = G.num_layers,\n",
    "                 num_heads = G.num_heads,\n",
    "                 dense_dim = G.dense_dim,\n",
    "                 max_positional_encoding_input = G.window_size,\n",
    "                 max_positional_encoding_target = G.window_size,\n",
    "                 dropout_rate=0.1,\n",
    "                 batchnorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "\n",
    "#         self.decoder = Decoder() # No Decoder is the method used by Hannan et al in the Journal Nature\n",
    "\n",
    "\n",
    "        self.final_stack = tf.keras.Sequential(tf.keras.layers.Dense(dense_dim,activation = \"relu\"),\n",
    "                                               tf.keras.layers.Dense(1, activation = \"relu\")\n",
    "                                              )\n",
    "    \n",
    "    def call(self, x, y, training, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_data -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "                              An array of the windowed voltage, current and time data\n",
    "            output_soc -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask -- Boolean mask to ensure that the padding is not treated as part of the input\n",
    "            look_ahead_mask -- Boolean mask for the target_input\n",
    "            dec_padding_mask -- Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output -- SOC prediction at time t\n",
    "            attention_weights - Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        enc_output = self.encoder(x, training) # (G.batch_size, G.dense_dim)\n",
    "        \n",
    "#         dec_output, attention_weights = self.decoder(output_sentence, enc_output, training,\n",
    "#                                                      look_ahead_mask, dec_padding_mask)\n",
    "#         assert dec_output.shape == \n",
    "        \n",
    "        final_output = self.final_dense(enc_output) # (G.batch_size, 1)\n",
    "\n",
    "    \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.random.uniform((G.batch_size, G.window_size, G.num_features))\n",
    "y = tf.random.normal((G.batch_size,1))\n",
    "# Don't need padding masks for battery data because the zeros are important values\n",
    "# enc_padding_mask = create_padding_mask(x)\n",
    "# dec_padding_mask = create_padding_mask(y)\n",
    "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
    "\n",
    "\n",
    "t = Transformer()\n",
    "x = t(x,y,True, look_ahead_mask, dec_padding_mask)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"train\"></a>\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.optimizers.Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1,\n",
    "                                     beta1 = 0.9,\n",
    "                                     beta2 = 0.999\n",
    "                                    )\n",
    "loss_fn = tf.keras.losses.LogCosh()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
